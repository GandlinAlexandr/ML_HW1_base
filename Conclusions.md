## Что было сделано
* С помощью `ydata-profilling` были построены дашборды как для тренировочных, так и для тестовых данных.
* В процессе работы была осуществлена обработка признаков датасета. В результате которой строковые призаки были переведены в числовые. Были удалены дубликаты.
* Было осуществлено заполнение пропусков медианами. Причём пропуски в тестовых данных были заполнены медианами из тренировочных данных.
* Был проведён базовый анализ данных: расчитаны меры изменчивости и центральной тенденции для каждого признака. Были построены pairplot, рассчитаны коэфиициенты корреляций (Пирсона, V-мера Крамера, $\phi_k$), по ним построены типловые карты.
* Была обучена модель линейной регрессии на вещественных признаках с применением скалирования, выведены коэффициенты модели, расччитаны метрики $R^2$ и MSE.
* Была проведена кросс-валидация с помощью `GridSearchCV` и `ElasticNet` для оптимального подбора параметров модели Lasso-регрессии.
* Применили OneHot-кодирование для обработки категориальных признаков. Были подобраны параметры для Ridge-регрессии.
* Был запрограммирован рассчёт метрики `business_metric`. Была выбрана наилучшая по этой метрике модель из обученных ранее.
* Был реализован сервис FastAPI.

## C какими результатами
* В результате получен предобработанный датасет, готовый к дальнейшей работе.
* Были обычены четыре регрессионные модели: обычная линейная регрессия, Lasso-регрессия, ElasticNet-регрессия и Ridge-регрессия.
* Выяснилось, что регуляризация не зануляла весов модели. Это было связано с коэффициентом `alpha`, который оказался маловат для зануления. Если же его поднять до 10000, то регуляризация сильнее начнёт влиять на веса модели и обнулять их, однако вызовет её ухудшение. По этой причине я не стал включать большие значения `alpha`. В нашей модели нет малозначимых весов (по модулю они большие и вцелом сопоставимые), а потому регуляризация с параметрами по умолчанию и малыми значениями `alpha` не влияла на модели.
* Также выяснены особенности обучения `OneHotEncoder`, связанные с разной представленностью значений категориальных признаков в тренировочным и тестовом датасетах.
* Выяснил, что простое логарифмирование может очень сильно поменять модель.

Я предобработал `name`: удалил все наименования моделей автомобилей и оставил лишь марки, так как по идее марка может сильно влиять на цену автомобиля (полагаю, цена её модели скорее зависит от года выпуска). А далее я кодировал значения TargetEncoding. Я перебирал разные гиперпараметры для кодирования и модели. Однако в итоге всё равно получал неплохой коэффициент детерминации, но отличающиеся в два раза (в лучшем случае) MSE на тренировочных и тестовых данных. Это свидетельствует о переобучении. Разные модели дают схожий результат. В итоге решил зафиксировать наименьшее соотношение MSE (примерно в 2 раза различие) и перебирал гиперпараметры по кодированию `name` (на сетке подобрать не догадался). В итоге следил, чтобы MSE не выходило сильно за минимальное соотношение, чтобы был максимальный коэффициент детерминации и чтобы на трейне и тесте он не сильно различался. Итог:

`Train	MSE: 74391927133.7783  R^2: 0.7405`

`Test	MSE: 154111812071.4764	R^2: 0.7319`.

Позже, за несколько часов до дедлайна, я решил логарифмировать таргет. И модель значительно улучшилась:

`Train	MSE: 0.08599	R^2: 0.85285`

`Test	MSE: 0.08073	R^2: 0.88714`.

## Что дало наибольший буст в качестве
Наибольший буст в качества дали добавление категориальных признаков после OneHot-кодирования (проверил до обработки `name`, но код в блокнот не вошёл) и логарифмирование целевой переменной. Причём последнее внесло максимальный положительный эффект. На важность категориальных признаков указывали также довольно большие корреляции некоторых из них с целевой переменной. Наименее слабый, но всё же буст качества, дала предобработка `name` и TargetEncoding этого столбца с применением регуляризации.
